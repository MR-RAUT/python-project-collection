# ğŸ“¦ FastBox â€“ Mystery Delivery System (Python)

A logistics simulation system that models one day of package delivery operations for a fictional company called **FastBox**.
The system assigns packages to delivery agents based on proximity, simulates deliveries, measures efficiency, and generates detailed reports.

This project is designed to be closely resembling real-world backend logic.

---

## ğŸ§  Problem Overview

FastBox operates with:

* Multiple **warehouses**
* Multiple **delivery agents**
* Multiple **packages**

### Objectives:

1. Read and parse JSON input data
2. Assign each package to the nearest agent (Euclidean distance)
3. Simulate delivery routes
4. Calculate total distance traveled per agent
5. Identify the most efficient agent
6. Generate reports in JSON and CSV formats
7. Validate correctness using multiple test cases

---

## ğŸ“ Project Structure

```bash
fastbox-mystery-delivery/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # JSON loader
â”‚   â”œâ”€â”€ distance.py           # Euclidean distance logic
â”‚   â”œâ”€â”€ assignment.py         # Package â†’ Agent assignment
â”‚   â”œâ”€â”€ simulation.py         # Delivery simulation (+ delay)
â”‚   â””â”€â”€ report.py             # JSON & CSV report generator
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.json             # Original assignment input
â”‚
â”œâ”€â”€ Test_cases/
â”‚   â”œâ”€â”€ test_case_1.json
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ test_case_10.json     # Scenario-based test cases
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ report.json
â”‚   â”œâ”€â”€ top_agent.csv
â”‚   â””â”€â”€ test_case_report/
â”‚       â”œâ”€â”€ test_case_1_report.csv
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ test_case_10_report.csv
â”‚
â”œâ”€â”€ base_case.json            # Sanity / demo input
â”œâ”€â”€ main.py                   # Main execution file
â”œâ”€â”€ test_runner.py            # Automated test runner
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ System Flow

JSON Input
   â†“
Data Loading
   â†“
Agentâ€“Package Assignment
   â†“
Delivery Simulation
   â†“
Efficiency Calculation
   â†“
Report Generation (JSON / CSV)
   â†“
Test Case Validation

---

## ğŸ“ Distance Calculation

Euclidean distance is used to determine proximity:

distance = âˆš((xâ‚‚ âˆ’ xâ‚)Â² + (yâ‚‚ âˆ’ yâ‚)Â²)

This is used for:

* Agent â†’ Warehouse
* Warehouse â†’ Destination

---

## ğŸ“Š Efficiency Metric

Each agentâ€™s efficiency is calculated as:

efficiency = total_distance / packages_delivered


* Lower efficiency = better performance
* Agents with zero deliveries are excluded
* This avoids unfair comparison based only on volume

---

## ğŸ† Best Agent Selection

The **best agent** is defined as:

> The agent who delivers packages using the least distance per delivery.

This reflects real-world logistics optimization.

---

## ğŸ§ª Testing Strategy

### âœ” Scenario-Based Testing

* All test cases are stored as JSON files
* Each file represents a full day of operations
* Tests validate that **all packages are delivered**

### âœ” Automated Validation

* PASS / FAIL based on expected vs delivered packages
* No manual verification required

### âœ” CSV Report Per Test Case

For each test case, a CSV report is generated:

output/test_case_report/test_case_X_report.csv

Each CSV includes:

* Agent ID
* Packages delivered
* Total distance
* Efficiency
* Best agent status

---

## ğŸ”„ Data Normalization

Some test cases use legacy or alternative JSON formats.

To ensure stability:

* Input data is normalized inside the test runner
* Core business logic remains unchanged
* Prevents schema-related runtime errors

This mirrors real-world systems that accept data from multiple sources.

---

## â­ Bonus Features Implemented

* âœ… **Random delivery delays** (optional, realistic simulation)
* âœ… **Mid-day agent joining** (data-driven, no logic change)
* âœ… **CSV export for analytics**
* âœ… **Best agent tagging**
* âœ… **Multiple input schemas supported**

---

## â–¶ï¸ How to Run

### Run base case / demo:

```bash
python main.py
```

### Run all test cases:

```bash
python test_runner.py
```

---

## ğŸ“¦ Outputs

* `output/report.json` â€“ Main summary report
* `output/top_agent.csv` â€“ Agent performance summary
* `output/test_case_report/*.csv` â€“ Per-test analytics

---

## ğŸ¤ Explanation (Short)

> â€œI designed the system with modular components and scenario-based testing. Inputs are normalized for consistency, deliveries are simulated realistically, and performance metrics are exported for analysis. The system is data-driven and easy to extend.â€

---

## âœ… Key Engineering Highlights

* Modular design
* Clean separation of concerns
* Data-driven logic
* Scalable testing approach
* Real-world efficiency metric
* Clear debugging and validation flow

---

## ğŸ Final Notes

* All requirements from the assignment are fully implemented
* Bonus features are included without breaking core logic
* The project is production-style, testable, and interview-ready

---


